{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89ebb92f",
   "metadata": {},
   "source": [
    "# Notebook for training/testing MLP network\n",
    "\n",
    "We train a set of `MLP` networks on different datasets (**for different N in system, N features uses - fixed**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fb5960",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-29T12:24:28.224297Z",
     "iopub.status.busy": "2022-04-29T12:24:28.224001Z",
     "iopub.status.idle": "2022-04-29T12:24:29.983159Z",
     "shell.execute_reply": "2022-04-29T12:24:29.982064Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from os.path import join as p_join\n",
    "\n",
    "##################################\n",
    "## GLOBAL SETTINGS ###############\n",
    "##################################\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41789d83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-29T12:24:29.999476Z",
     "iopub.status.busy": "2022-04-29T12:24:29.998883Z",
     "iopub.status.idle": "2022-04-29T12:24:30.860948Z",
     "shell.execute_reply": "2022-04-29T12:24:30.860068Z"
    }
   },
   "outputs": [],
   "source": [
    "###############################\n",
    "##### IMPORT DL Depensies #####\n",
    "###############################\n",
    "import torch\n",
    "\n",
    "def seed_all(seed=42):\n",
    "\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    print(\"[ Using Seed : \", seed, \" ]\")\n",
    "\n",
    "####################################\n",
    "#####   SEED ALL EXPERIMENTS   #####\n",
    "####################################\n",
    "seed_all()    \n",
    "\n",
    "data_path = p_join('..', '..', 'data')\n",
    "N_FEAT = 16                  # Set n_feat. parameter - uses for count central features\n",
    "#################################\n",
    "####### GLOBAL CONFIG ###########\n",
    "#################################\n",
    "CONFIG = {'ephs': 100,\n",
    "          'train_batch_size': 1024,\n",
    "          'test_batch_size': 64,\n",
    "          'cpu_workers': 2,\n",
    "          'save_ckpts': False,\n",
    "          'ckpt_save_folder': f'mlp_ckpts_feat_{N_FEAT}'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c19c83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-29T12:24:30.865188Z",
     "iopub.status.busy": "2022-04-29T12:24:30.864927Z",
     "iopub.status.idle": "2022-04-29T12:24:30.872725Z",
     "shell.execute_reply": "2022-04-29T12:24:30.871021Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../..\") # Adds higher directory to python modules path.\n",
    "from utils import utils\n",
    "from utils import dl_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffebe305",
   "metadata": {},
   "source": [
    "### Run training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ab9174",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Each subarray represent an experiment,\n",
    "### where N will be used for dataset creation \n",
    "N_SLICES = [[21, 22], [23, 24], [25, 26], [27, 28]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbf269d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "models, test_loaders = {}, {}\n",
    "for nums in N_SLICES:\n",
    "    n_global_str = '-'.join(map(str, nums))\n",
    "    CONFIG['ckpt_save_folder'] = f'mlp_ckpts_N_{n_global_str}_feat_{N_FEAT}'\n",
    "    CONFIG['experiment_name'] = f'N_C={N_FEAT}, N={n_global_str}'\n",
    "    print(f\"Starting {CONFIG['experiment_name']} ...\")\n",
    "\n",
    "    ################################\n",
    "    ####    Create dataset      ####\n",
    "    ################################\n",
    "    X, Y = utils.make_merged_dataset_by_N(data_path, nums, n_feat=N_FEAT)\n",
    "    train_dataloader, test_dataloader = utils.create_dataloaders(\n",
    "                                            X, Y,\n",
    "                                            cpu_workers=CONFIG['cpu_workers'],\n",
    "                                            train_bs=CONFIG['train_batch_size'],\n",
    "                                            test_bs=CONFIG['test_batch_size']\n",
    "                                        )\n",
    "\n",
    "\n",
    "    ################################\n",
    "    ####    Run training        ####\n",
    "    ################################\n",
    "    net = dl_models.MlpNetLight(in_features=N_FEAT)\n",
    "    utils.count_params(net)\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=CONFIG.get('lr', 5e-3))\n",
    "    score = utils.run_training(net, optimizer, CONFIG, train_dataloader, test_dataloader)\n",
    "\n",
    "    models[CONFIG['experiment_name']] = net\n",
    "    test_loaders[CONFIG['experiment_name']] = test_dataloader\n",
    "    results[CONFIG['experiment_name']] = {'Accuracy': score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b2e8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9652e1e9",
   "metadata": {},
   "source": [
    "### Cross dataset testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6357ab3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {exp_name: [] for exp_name in models}\n",
    "for exp_name in models:\n",
    "    net = models[exp_name]\n",
    "    for test_loader_name in test_loaders:\n",
    "        test_loader = test_loaders[test_loader_name]\n",
    "        test_score = utils.test_model(net, test_loader, device='cpu')\n",
    "        data[exp_name].append(test_score)\n",
    "        \n",
    "        \n",
    "df = pd.DataFrame.from_dict(data, orient='index',\n",
    "                            columns=[exp_name for exp_name in models])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ecd776",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_matshow(df, x_labels, y_labels, cmap_name='YlGn'):\n",
    "    fig, ax = plt.subplots()\n",
    "    cax = ax.matshow(df, cmap=plt.get_cmap(cmap_name))\n",
    "    fig.colorbar(cax)\n",
    "    ax.set_xticklabels(x_labels)\n",
    "    ax.set_yticklabels(y_labels)\n",
    "    ax.set_ylabel('Train')\n",
    "    ax.set_xlabel('Test')\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f7d491",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticks = ['-'.join(map(str, nums)) for nums in N_SLICES]\n",
    "fig_mlp, ax_mlp = plot_matshow(df, [' '] + ticks, [' '] + ticks)\n",
    "ax_mlp.set_title('Accuracy MLP')\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d999c485",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
